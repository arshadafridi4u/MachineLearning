{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTX9uzIdkUOAaY6Ssz0tLx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arshadafridi4u/MachineLearning/blob/master/Keras_RNN_sequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ41-WDgmm0n",
        "outputId": "f478d95c-3c6f-4621-dde1-f6688f1908d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 3s 3s/step - loss: 164.5171\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 163.5293\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 162.5451\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 161.5647\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 160.5881\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 159.6154\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 158.6465\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 157.6817\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 156.7208\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 155.7640\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 154.8112\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 153.8626\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 152.9180\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 151.9777\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 151.0415\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 150.1095\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 149.1817\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 148.2581\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 147.3388\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 146.4237\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 145.5128\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 144.6062\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 143.7038\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 142.8057\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 141.9117\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 141.0220\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 140.1364\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 139.2551\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 138.3779\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 137.5048\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 136.6358\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 135.7709\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 134.9100\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 134.0531\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 133.2003\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 132.3513\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 131.5063\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 130.6652\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 129.8278\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 128.9943\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 128.1645\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 127.3384\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 126.5159\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 125.6971\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 124.8817\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 124.0699\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 123.2616\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 122.4566\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 121.6550\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 120.8567\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 120.0616\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 119.2697\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 118.4810\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 117.6953\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 116.9127\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 116.1330\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 115.3563\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 114.5824\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 113.8113\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 113.0430\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 112.2774\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 111.5144\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 110.7541\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 109.9962\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 109.2409\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 108.4880\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 107.7375\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 106.9894\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 106.2436\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 105.5000\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 104.7586\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 104.0194\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 103.2824\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 102.5474\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 101.8145\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 101.0836\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 100.3547\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 99.6277\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 98.9026\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 98.1795\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 97.4582\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 96.7387\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 96.0210\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 95.3052\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 94.5911\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 93.8787\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 93.1681\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 92.4593\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 91.7521\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 91.0466\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 90.3429\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 89.6408\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 88.9404\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 88.2417\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 87.5446\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 86.8493\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 86.1556\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 85.4636\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 84.7733\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 84.0847\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 83.3977\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 82.7125\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 82.0290\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 81.3472\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 80.6672\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 79.9890\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 79.3124\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 78.6377\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 77.9648\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 77.2937\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 76.6244\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.9570\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 75.2915\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 74.6278\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 73.9661\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 73.3063\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 72.6485\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 71.9926\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 71.3388\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 70.6869\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 70.0372\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 69.3895\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 68.7439\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 68.1004\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 67.4591\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 66.8200\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 66.1831\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 65.5484\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 64.9160\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 64.2858\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 63.6580\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 63.0325\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 62.4094\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 61.7887\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 61.1704\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 60.5545\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 59.9412\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 59.3303\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 58.7220\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 58.1163\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 57.5131\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 56.9125\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 56.3146\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 55.7194\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 55.1269\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 54.5371\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 53.9500\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 53.3658\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 52.7843\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 52.2057\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 51.6299\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 51.0571\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 50.4871\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 49.9201\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 49.3560\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 48.7950\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 48.2369\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 47.6819\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 47.1300\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 46.5811\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 46.0354\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 45.4928\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 44.9534\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 44.4171\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 43.8841\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 43.3542\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 42.8277\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 42.3044\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 41.7843\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 41.2676\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 40.7543\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 40.2443\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 39.7376\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 39.2344\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 38.7345\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 38.2381\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 37.7451\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 37.2556\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 36.7696\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 36.2871\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 35.8080\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 35.3325\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 34.8606\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 34.3922\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 33.9273\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 33.4661\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 33.0084\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 32.5544\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 32.1040\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 31.6572\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 31.2140\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 30.7745\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 30.3387\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 29.9065\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 29.4780\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 29.0532\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 28.6321\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 28.2147\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 27.8010\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 27.3910\n",
            "Predicted values: [ 0.92782265  1.5245453   2.121268    2.7179906   3.3147135   3.911436\n",
            "  4.508159    5.104882    5.7016034   6.298326    6.8950496   7.491772\n",
            "  8.088494    8.685217    9.2819395   9.878661   10.475385   11.072106\n",
            " 11.66883   ]\n",
            "Next value after 20: 12.265552\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Dense\n",
        "\n",
        "# Step 1: Import Libraries\n",
        "import tensorflow as tf\n",
        "\n",
        "# Step 2: Prepare the Dataset\n",
        "# Create a simple sequence dataset\n",
        "def create_dataset(seq_length):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(seq_length) - 1):\n",
        "        X.append(seq_length[i])\n",
        "        y.append(seq_length[i + 1])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Sample sequence\n",
        "seq_length = np.array([i for i in range(1, 21)])  # Sequence from 1 to 20\n",
        "X, y = create_dataset(seq_length)\n",
        "\n",
        "# Reshape input to be [samples, time steps, features]\n",
        "X = X.reshape((X.shape[0], 1, 1))\n",
        "\n",
        "# Step 3: Build the RNN Model\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(10, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Step 4: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 5: Train the Model\n",
        "model.fit(X, y, epochs=200, verbose=1)\n",
        "\n",
        "# Step 6: Evaluate the Model\n",
        "# Predict the next value in the sequence\n",
        "predicted = model.predict(X, verbose=0)\n",
        "print(\"Predicted values:\", predicted.flatten())\n",
        "\n",
        "# To predict the next value beyond the current sequence:\n",
        "next_input = np.array([[20]])\n",
        "next_input = next_input.reshape((1, 1, 1))\n",
        "next_value = model.predict(next_input, verbose=0)\n",
        "print(\"Next value after 20:\", next_value.flatten()[0])\n"
      ]
    }
  ]
}